Title:force usage of F16 textures

Body:tfjs-core: Make it possible to force usage of F16 textures. #1902https://github.com/tensorflow/tfjs/pull/1902appears in tf-core 1.2.9 release (only f16 textures yet; not math!).1. can you (we :) add and test f16 textures?2. they added in "To Do": "Add flag (defaults to false) that would turn on mediump precision." Can we confirm; that mediump precision is useful in real aplications? (than they will add the flag more quickly :)E.g. image classification/detection + colab + NVIDIA GPU?

Comment:['So you are asking me to upgrade the tfjs-core version to latest?====='; "not sure about detailes (I'm from webgl-dev-list https://www.ibiblio.org/e-notes/webgl/gpu/mul/sgemm.htm )1. if you just add  tf.webgl.forceHalfFloat()you will half GPU memory footprint; get ~10% acceleration and save battery.2. with mediump precision you can get x2 acceleration but for some reason e.g. SSD model works wrong with fp16 math (for TFjs team). Can we optimize any useful model for fp16 math (NVIDIA can :)? More detailes?====="; "These flags you are talking about can be enabled via tf. face-api.js doesn't deal with such kind of things; it just utilizes tfjs as a backend. So you can simply enable those flags via tf and the models of face-api.js will make use of them. > with mediump precision you can get x2 acceleration but for some reason e.g. SSD model works wrong with fp16 math (for TFjs team). Can we optimize any useful model for fp16 math (NVIDIA can :)? More detailes?I am not familar with such kind of optimizations. Again such optimizations are probably something that have to be done in the tfjs backend and not face-api.js; but correct me if I am wrong.====="]