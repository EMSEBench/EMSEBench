Title:Same image after first prediction returns different [x;y;z] values for face-landmarks-detection model

Body:**System information**- Custom code- OS Platform and Distribution (MacOs BigSur):- TensorFlow.js installed from npm (latest)- Browser version: Chrome 93 StableFrom my package.json:``` "dependencies": {    "@material-ui/core": "^4.12.3";    "@material-ui/icons": "^4.11.2";    "@tensorflow-models/face-landmarks-detection": "0.0.1";    "@tensorflow/tfjs-backend-cpu": "^3.8.0";    "@tensorflow/tfjs-backend-wasm": "^3.8.0";    "@tensorflow/tfjs-backend-webgl": "^2.4.0";    "@tensorflow/tfjs-converter": "^2.4.0";    "@tensorflow/tfjs-core": "^2.4.0";    "axios": "^0.21.1";    "react": "^17.0.2";    "react-dom": "^17.0.2";    "react-redux": "^7.2.4";    "react-router-dom": "^5.2.0";    "react-scripts": "^4.0.3"  };```I have an image uploader using reactJs. All I'm doing is selecting an image file; creating an image element from with the img.src as the base64 encoded data of the image and passing it through the model to detect the landmark coordinates for that image.```async function predictImage(file) {      return new Promise((rs; rj) => {        try {          const imageElement = document.createElement("img");          imageElement.src = file;          imageElement.onload = async () => {           const preds = await model.estimateFaces({             input: imageElement;           });          return rs();        };        } catch (err) {          return rj(err);        }      });    }```I then store a selected set from the scaled mesh obj in a database for later comparison.Given image A and image B;Image A: ![jackie1](https://user-images.githubusercontent.com/5845311/133072304-a54731e8-5463-4cf6-a2c8-d5ef5dd1774a.jpeg)Image B: ![salma1](https://user-images.githubusercontent.com/5845311/133072332-22fead35-b7e5-4d14-b845-b59c79947d0a.jpg)If I run image A for the first time after loading the model I get a set of values; say from key point 6 from the [face mesh](https://github.com/tensorflow/tfjs-models/blob/master/face-landmarks-detection/mesh_map.jpg) provided; `[674.8491821289062;452.3935241699219;-8.618978500366211]`. I then upload image B and run it through the model without restarting or refreshing the page. If I then upload image A again; the values for the same key point 6 are now different from the first prediction of image A; `[336.6038818359375;387.3382263183594;-14.38083553314209]`.More extensive list of the key point values from initial upload and secondary upload:![Screenshot 2021-09-13 at 12 03 11](https://user-images.githubusercontent.com/5845311/133072756-7c681f50-dfd1-4828-b9e8-8e37cd05e66a.png)If I then refresh my page and upload image A; the values will match the first upload from the previous attempt.I have checked my upload logic to make sure I am not overlapping my images in any way and that I am passing a clean image to the model.Is this the expected behaviour? What would explain this behaviour? Has anyone else encountered this issue?

Comment:["Thanks for the question; @hyprstack. face-landmarks-detection is actually stateful; i.e. past inputs to the model can affect future predictions. This is because the model pipeline [caches regions of interest](https://github.com/tensorflow/tfjs-models/blob/master/face-landmarks-detection/src/mediapipe-facemesh/pipeline.ts#L430-L460) and then [runs landmark detection on just those regions](https://github.com/tensorflow/tfjs-models/blob/master/face-landmarks-detection/src/mediapipe-facemesh/pipeline.ts#L300-L304). I think this is done for performance reasons when running on a video stream; and it allows the pipeline to avoid running face detection if faces have not moved; although I'm not 100% sure (@lina128 would know more). @lina128 do you know of a way to avoid this caching in case a user wants to run the model on several separate static images?====="; "We'll add a staticImage option to the API soon.====="; 'Thanks @mattsoulanille & @lina128 . Makes sense to optimise it like that. Will wait for the update for now :)=====']