Title:[webgpu]fall back to cpu or webgl

Body:**System information**- Have I written custom code (as opposed to using a stock example script provided in TensorFlow.js):yes; tfjs functional api model with custom layersself browserified tfjs-backend-webgpu github pull- OS Platform and Distribution (e.g.; Linux Ubuntu 16.04):chrome canary windows- TensorFlow.js installed from (npm or script link):link https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js at time of writing 3.7- TensorFlow.js version (use command below):3.7- Browser version:Version 93.0.4533.0 (Official Build) canary (64-Bit)**Describe the current behavior**model is running fine with webglif i change backend to webgpu on unsafe canary; following error shows up:Error: Kernel 'LogicalAnd' not registered for backend 'webgpu'**Describe the expected behavior**i know webgpu is at an alpha stage - but why doesn't it fall back to cpu or webgl for that part? am i missing something**Standalone code to reproduce the issue**i can provide the browserified version of the webgpu-backend; if needed.

Comment:["i also tried with tf.env().set('WEBGPU_CPU_FORWARD'; true); but no effect.====="; "@BenjaminWegener Thanks for trying the webgpu backend. Current; the supported kernels are limited in webgpu. You can find all supported kernels [here](https://github.com/tensorflow/tfjs/blob/master/tfjs-backend-webgpu/src/register_all_kernels.ts). `LogicalAnd` is not supported yet. But it's easier to be added. >i also tried with tf.env().set('WEBGPU_CPU_FORWARD'; true); but no effect.Setting `WEBGPU_CPU_FORWARD` true doesn't mean to fall back to cpu. It's just one of the conditions that it will run to cpu. Only if [all conditions](https://github.com/tensorflow/tfjs/blob/master/tfjs-backend-webgpu/src/backend_webgpu.ts#L837) are satisfied (it is based on performance consideration); it will go the cpu path. But all of these are based on that the corresponding kernel has been registered. > fall back to cpu or webgl.In our current design; we should register the kernel first. Then we can choose to fall back to cpu or use the backend implementation in the kernel config file. So the fix is to register the missed kernel for webgpu backend. ====="; 'Thank you for your answer. I need `tf.LogicalAnd` and `tf.Tile`. I will have to wait.====='; '@BenjaminWegener `tf.LogicalAnd` and `tf.Tile` are supported now in webgpu. Please let us know if you still meet any problems. Thanks.====='; 'Thank you very much; it really helps.If i run my model; the next Problem is`UnsortedSegmentSum`.====='; '...====='; "@BenjaminWegener Do you mind to share more information about your model? Do you see any bad performance on webgl so that you want to try webgpu? Currently our main efforts are on performance . We want to make sure that webgpu really brings great performance when it's officially released.  But the supported ops may be not full. So I want to know the gap to enable your model. ====="; "no problem. i am trying to implement a transformer like model in tfjs. just download or clone the repo an try it out. use chrome w/ webgpu .https://github.com/BenjaminWegener/transformer-tfjsthe model runs fine with ~6gig of GPU memory with webgl; i just wanted to try the speed of webgpu. so no; it isn't crucial to me; that it runs with webgpu (yet).thank you for your support-====="; "@BenjaminWegener Can you review your model and list all the needed ops so that we can know the overall gap in webgpu? It's not efficient for us to implement these ops one by one. If you can provide the overall status; we can evaluate our efforts and give you better support.====="; 'I stripped everything unneccesary from the model. Looks like tf.layers.embedding uses `UnsortedSegmentSum`; which is the only OP my model is missing. But I cannot tell; if tf.layers.embedding uses another unsupported OP.====='; "i replaced the embedding layer with a feedforward net. (dense-activation-dense). but if i use 'relu' activation like `tf.layers.dense({units: UNITS; activation: 'relu'}).apply(x)` i get the error that op `Step` isn't implemented. so i replace that with a custom gelu activation; which seems to be working. so for now i'm closing this. thank you for your help!====="; "@BenjaminWegener Glad to know that you work around this issue. We'd like to hear your experience on webgpu. Do you see any perf issue with your model on webgpu? Please feel free to file bugs if you see any problems :) ====="]